# -*- coding: utf-8 -*-
"""DCGAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ijWGKbZ5VF4TbB3rGwf9jbYl9o86ODg5
"""

# Commented out IPython magic to ensure Python compatibility.
import random
import matplotlib.animation as animation
from IPython.display import HTML
import numpy as np
import torch
from torch import optim
import torchvision
import torch.nn as nn
import torchvision.datasets as dsets
import torchvision.utils as vutils
import torchvision.transforms as transforms
from IPython import display
from torch.autograd import Variable
import matplotlib.pyplot as plt
# %matplotlib inline

manualSeed = 777 
random.seed(manualSeed) 
torch.manual_seed(manualSeed)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

nz = 100 # 노이즈 벡터의 크기
nc = 3 # 채널의 수
ngf = 128 # generator 필터 조정
ndf = 64 # discriminator 필터 조정
num_epochs = 15 # 에폭 수
lr = 0.0002
beta1 = 0.5

image_size = 64 # 만들어지는 이미지의 크기
batch_size = 128 # 미니배치의 크기

transform = transforms.Compose([
        transforms.Scale(64),
        transforms.ToTensor(),                     
        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))
])

train_dataset = dsets.CIFAR10(root='./data/', train=True, download=True, transform=transform)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size= batch_size, shuffle=True)

def weights_init(m):
  classname = m.__class__.__name__

  if classname.find('Conv') != -1:         # Conv weight init
    nn.init.normal_(m.weight.data, 0.0, 0.02)

  elif classname.find('BatchNorm') != -1:  # BatchNorm weight init
    nn.init.normal_(m.weight.data, 1.0, 0.02)
    nn.init.constant_(m.bias.data,0)

class Generator(nn.Module): 
  def __init__(self):
    super(Generator, self).__init__() 
    self.main = nn.Sequential( # input : z 벡터 
                              nn.ConvTranspose2d(in_channels=nz, out_channels=ngf*8, kernel_size=4, stride=1, padding=0, bias=False),
                              nn.BatchNorm2d(ngf*8), 
                              nn.ReLU(True),

                              # state size. (ngf*8) * 4 * 4 
                              nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False), 
                              nn.BatchNorm2d(ngf*4), 
                              nn.ReLU(True), 

                              # (ngf*8) * 8 * 8 
                              nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False), 
                              nn.BatchNorm2d(ngf*2), 
                              nn.ReLU(True), 

                              # (ngf*2) * 16 * 16 
                              nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False), 
                              nn.BatchNorm2d(ngf), 
                              nn.ReLU(True), 

                              # ngf * 32 * 32 
                              nn.ConvTranspose2d(ngf,nc,4,2,1,bias=False), 
                              nn.Tanh() 
                              # nc * 64 * 64 
                              ) 
                        
  def forward(self,input): 
    return self.main(input)

netG=Generator().to(device)
netG.apply(weights_init)
print(netG)

class Discriminator(nn.Module):
  def __init__(self): 
    super(Discriminator, self).__init__()
    self.main = nn.Sequential( # input : nc * 64 * 64 
                              nn.Conv2d(nc, ndf, 5, 2, 2, bias=False), 
                              nn.LeakyReLU(0.2, inplace=True), 

                              # ndf * 32 * 32 
                              nn.Conv2d(ndf,ndf*2, 5, 2, 2, bias=False), 
                              nn.BatchNorm2d(ndf*2), 
                              nn.LeakyReLU(0.2, inplace=True), 

                              # (ndf*2) * 16 *16 
                              nn.Conv2d(ndf*2, ndf*4, 5, 2, 2, bias=False), 
                              nn.BatchNorm2d(ndf*4), 
                              nn.LeakyReLU(0.2, inplace=True), 

                              # (ndf*4) * 8 * 8 
                              nn.Conv2d(ndf*4, ndf*8, 5, 2, 2, bias=False), 
                              nn.BatchNorm2d(ndf*8), 
                              nn.LeakyReLU(0.2, inplace=True), 

                              # (ndf*8) * 4 * 4 
                              nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=False), 
                              nn.Sigmoid()
                              ) 
    
  def forward(self,input): 
    return self.main(input)

netD = Discriminator().to(device)
netD.apply(weights_init)
print(netD)

criterion = nn.BCELoss()

fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)

real_label=1
fake_label=0

optimizer_D = optim.Adam(netD.parameters(),lr=lr, betas=(beta1,0.999))
optimizer_G = optim.Adam(netG.parameters(),lr=lr, betas=(beta1,0.999))

# Training 
img_list = [] 
G_losses = [] 
D_losses = [] 

for epoch in range(num_epochs): 
  G_loss=0
  D_loss=0
  Dx=0
  DGz1=0
  DGz2=0
  for i, data in enumerate(train_loader):

    # Update D
    netD.zero_grad() 
    real_cpu = data[0].to(device) 
    b_size = real_cpu.size(0) 
    label_real=torch.ones(b_size).to(device)
    
    output = netD(real_cpu).view(-1) 
    errD_real = criterion(output,label_real) 
     
    D_x = output.mean().item()

    noise = torch.randn(b_size,nz,1,1,device=device) 
    fake = netG(noise) 
    label_fake=torch.zeros(b_size).to(device)
    output = netD(fake.detach()).view(-1) 
    errD_fake = criterion(output,label_fake) 
     
    D_G_z1 = output.mean().item()

    errD = errD_real + errD_fake 
    errD.backward()
    optimizer_D.step()

    # Update G 
    netG.zero_grad() 
    output = netD(fake).view(-1) 
    errG = criterion(output,label_real) 
    errG.backward() 
    D_G_z2 = output.mean().item() 

    optimizer_G.step()
    
    G_loss += errG.item()
    D_loss += errD.item()
    Dx += D_x
    DGz1 += D_G_z1
    DGz2 += D_G_z2

    if i % 50==49:
      print('[%2d/%2d][%3d/%3d]\tLoss_D: %.4f,\tLoss_G: %.4f,\tD(x): %.4f\tD(G(z)): %.4f / %.4f' % (epoch+1, num_epochs, i+1, len(train_loader), D_loss/50, G_loss/50, Dx/50, DGz1/50, DGz2/50))
      G_losses.append(G_loss/50)
      D_losses.append(D_loss/50)
      G_loss=0
      D_loss=0
      Dx=0
      DGz1=0
      DGz2=0

  with torch.no_grad():
    fake=netG(fixed_noise)
  img_list.append(vutils.make_grid(fake, padding=2, normalize=True))
  plt.figure(figsize=(5,10))
  plt.axis("off") 
  plt.title("Epoch : %2d"%(epoch+1)) 
  plt.imshow(np.transpose(img_list[-1].cpu(),(1,2,0))) 
  plt.show()

plt.figure(figsize=(10,5)) 
plt.title("Generator and Discriminator Loss During Training") 
plt.plot(G_losses,label="G") 
plt.plot(D_losses,label="D") 
plt.xlabel("iterations") 
plt.ylabel("Loss") 
plt.legend() 
plt.show()

fig = plt.figure(figsize=(5,10)) 
plt.axis("off") 
ims = [[plt.imshow(np.transpose(i.cpu(),(1,2,0)), animated=True)] for i in img_list] 
ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True) 
HTML(ani.to_jshtml())

real_batch=next(iter(train_loader))
plt.figure(figsize=(10,10))
plt.subplot(1,2,1)
plt.axis("off")
plt.title("Real Images")
plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:128], padding=5, normalize=True).cpu(),(1,2,0)))


plt.subplot(1,2,2)
plt.axis("off") 
plt.title("Fake Images") 
plt.imshow(np.transpose(img_list[-1].cpu(),(1,2,0))) 
plt.show()